{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb33dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import cv2\n",
    "from numpy import asarray, savez_compressed, load, expand_dims, save,array\n",
    "from PIL import Image, ImageDraw\n",
    "import albumentations as A\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b95186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(224,224)):\n",
    "    # load image from file\n",
    "    image = cv2.imread(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector using default weights\n",
    "    detector = mtcnn.MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    face_array = []\n",
    "    # extract the bounding box from the first face\n",
    "    for res in results:\n",
    "        x1, y1, width, height = res['box']\n",
    "        # confidence\n",
    "        confidence = res['confidence']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1+width, y1+height\n",
    "        # greater than 0.95\n",
    "        if confidence > 0.85:\n",
    "            # extract the face\n",
    "            face = pixels[y1:y2, x1:x2]\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f6533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fb79d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcn = MTCNN(margin=14,factor=0.6,keep_all=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2636193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fast_face(filename, required_size=(224,224)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pixels = asarray(img_rgb)\n",
    "    boxes, _ = mtcn.detect(pixels)\n",
    "    face_array = []\n",
    "    for c, i in enumerate(_):\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = f.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2575f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    #enumerate files\n",
    "    for filename in os.listdir(directory):\n",
    "        # path\n",
    "        path = os.path.join(directory, filename)\n",
    "        # get face\n",
    "        face = extract_fast_face(path)\n",
    "        # append all faces in an image into new faces array\n",
    "        for pixel in face:\n",
    "            faces.append(pixel)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea7981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Blur(blur_limit=3),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "#     A.OneOf([\n",
    "#             A.MotionBlur(p=0.2),\n",
    "#             A.MedianBlur(blur_limit=3, p=0.1),\n",
    "#             A.Blur(blur_limit=3, p=0.1),\n",
    "#         ], p=0.2),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c70986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset that contains one subdir  for each class that in turn contains images\n",
    "def load_dataset(dir_):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in os.listdir(dir_):\n",
    "        # path\n",
    "        path = os.path.join(dir_, subdir)\n",
    "        # skip any files that might be in the dir\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "#         if subdir != 'Atif Tahir':\n",
    "#             continue\n",
    "        faces = load_faces(path)\n",
    "        new_faces = faces[:]  \n",
    "        #augmentation\n",
    "        if len(new_faces) < 2:\n",
    "            k = 90\n",
    "        elif len(new_faces) < 7:\n",
    "            k = 30\n",
    "        else:\n",
    "            k = 2\n",
    "        for face in faces:\n",
    "            for i in range(k):\n",
    "                transformed = transform(image=face)\n",
    "                new_faces.append(transformed['image'])\n",
    "        # create labels \n",
    "        labels = [subdir for _ in range(len(new_faces))]\n",
    "        # summarize progress\n",
    "        print(f\"loaded {len(new_faces)} examples for class {subdir}\")\n",
    "        # store\n",
    "        X.extend(new_faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ee3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 91 examples for class Aashir\n",
      "loaded 91 examples for class Abeer\n",
      "loaded 91 examples for class Anam Qureshi\n",
      "loaded 91 examples for class Anaum Hamid\n",
      "loaded 91 examples for class Aqsa Zahid\n",
      "loaded 91 examples for class Atiya\n",
      "loaded 91 examples for class Bakhtawer\n",
      "loaded 91 examples for class Basit Ali\n",
      "loaded 91 examples for class Danish\n",
      "loaded 91 examples for class Dr. Aqsa Aslam\n",
      "loaded 186 examples for class Dr. Atif\n",
      "loaded 91 examples for class Dr. Fahad Sherwani\n",
      "loaded 91 examples for class Dr. Farooque\n",
      "loaded 91 examples for class Dr. Farrukh Hassan\n",
      "loaded 91 examples for class Dr. Farrukh Salim\n",
      "loaded 91 examples for class Dr. Farrukh Shahid\n",
      "loaded 91 examples for class Dr. Ghufran\n",
      "loaded 91 examples for class Dr. Jawwad\n",
      "loaded 91 examples for class Dr. Nadeem Kafi\n",
      "loaded 91 examples for class Dr. Nausheen\n",
      "loaded 91 examples for class Dr. Nouman\n",
      "loaded 91 examples for class Dr. Usama\n",
      "loaded 91 examples for class Dr. Waheed\n",
      "loaded 91 examples for class Dr. Zulfiqar\n",
      "loaded 91 examples for class Erum\n",
      "loaded 91 examples for class Fizza\n",
      "loaded 91 examples for class Hajra\n",
      "loaded 91 examples for class Hamza Ahmed\n",
      "loaded 91 examples for class Hassan\n",
      "loaded 91 examples for class Jamil\n",
      "loaded 91 examples for class Javeria Iftikhar\n",
      "loaded 91 examples for class Kashan\n",
      "loaded 91 examples for class M. Shahzad\n",
      "loaded 91 examples for class Mafaza\n",
      "loaded 91 examples for class Musawar\n",
      "loaded 91 examples for class Nida Munawar\n",
      "loaded 91 examples for class Rabia Tabassum\n",
      "loaded 91 examples for class Romasha\n",
      "loaded 91 examples for class Safia\n",
      "loaded 91 examples for class Shaharbano\n",
      "loaded 91 examples for class Shoaib Rauf\n",
      "loaded 91 examples for class Sobia\n",
      "loaded 91 examples for class Sohail\n",
      "loaded 91 examples for class Zain\n",
      "loaded 91 examples for class Zumar\n",
      "(4190, 224, 224, 3) (4190,)\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "trainX, trainy = load_dataset(\"data/train/\")\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce73f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1 examples for class Aashir\n",
      "loaded 5 examples for class Abdul Rehman\n",
      "loaded 1 examples for class Abeer\n",
      "loaded 11 examples for class ahmed\n",
      "loaded 7 examples for class Ahmed Naeem\n",
      "loaded 1 examples for class Anam Qureshi\n",
      "loaded 1 examples for class Anaum Hamid\n",
      "loaded 1 examples for class Aqsa Zahid\n",
      "loaded 1 examples for class Atiya\n",
      "loaded 1 examples for class Bakhtawer\n",
      "loaded 1 examples for class Basit Ali\n",
      "loaded 1 examples for class Danish\n",
      "loaded 1 examples for class Dr. Aqsa Aslam\n",
      "loaded 2 examples for class Dr. Atif\n",
      "loaded 1 examples for class Dr. Fahad Sherwani\n",
      "loaded 1 examples for class Dr. Farooque\n",
      "loaded 1 examples for class Dr. Farrukh Hassan\n",
      "loaded 1 examples for class Dr. Farrukh Salim\n",
      "loaded 1 examples for class Dr. Farrukh Shahid\n",
      "loaded 1 examples for class Dr. Ghufran\n",
      "loaded 1 examples for class Dr. Jawwad\n",
      "loaded 1 examples for class Dr. Nadeem Kafi\n",
      "loaded 1 examples for class Dr. Nausheen\n",
      "loaded 1 examples for class Dr. Nouman\n",
      "loaded 1 examples for class Dr. Usama\n",
      "loaded 1 examples for class Dr. Waheed\n",
      "loaded 1 examples for class Erum\n",
      "loaded 1 examples for class Fizza\n",
      "loaded 11 examples for class Fouzan\n",
      "loaded 1 examples for class Hajra\n",
      "loaded 1 examples for class Hamza Ahmed\n",
      "loaded 1 examples for class Hassan\n",
      "loaded 1 examples for class Jamil\n",
      "loaded 1 examples for class Kashan\n",
      "loaded 1 examples for class M. Shahzad\n",
      "loaded 1 examples for class Mafaza\n",
      "loaded 4 examples for class Mohib Rehman\n",
      "loaded 1 examples for class Musawar\n",
      "loaded 1 examples for class Nida Munawar\n",
      "loaded 1 examples for class Rabia Tabassum\n",
      "loaded 1 examples for class Romasha\n",
      "loaded 1 examples for class Safia\n",
      "loaded 1 examples for class Shaharbano\n",
      "loaded 1 examples for class Shoaib Rauf\n",
      "loaded 1 examples for class Sobia\n",
      "loaded 1 examples for class Sohail\n",
      "loaded 3 examples for class Sumair\n",
      "loaded 1 examples for class Zain\n",
      "loaded 7 examples for class Zulfiqar\n",
      "loaded 1 examples for class Zumar\n"
     ]
    }
   ],
   "source": [
    "testX, testy = load_dataset(\"data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f64b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('Backend/VGGFaceModelData/data.npz', trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34644f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract faces and calculate face embeddings for a list of photo files\n",
    "def get_embeddings(model,faces):\n",
    "    # convert into an array of samples\n",
    "    samples = faces.astype('float32')\n",
    "    samples = expand_dims(samples, axis=0)\n",
    "    # prepare the face for the model, e.g. center pixels\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "    # perform prediction\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6699375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ((4190, 224, 224, 3), (4190,))\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3468: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "(4190, 2048)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "data = load('Backend/VGGFaceModelData/data.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "# trainX, trainy = data['arr_0'], data['arr_1']\n",
    "print(f\"Loaded: {trainX.shape, trainy.shape}\")\n",
    "# print(f\"Loaded: {trainX.shape, trainy.shape}\")\n",
    "# load the facenet model\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embeddings(model,face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "# newTestX = list()\n",
    "# for face_pixels in testX:\n",
    "#     embedding = get_embeddings(model,face_pixels)\n",
    "#     newTestX.append(embedding)\n",
    "# newTestX = asarray(newTestX)\n",
    "# print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d237fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('Backend/VGGFaceModelData/faceEmbeddings_1.npz', newTrainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c2bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=(4450, 92)\n",
      "Accuracy: train=100.0, test=98.91304347826086\n"
     ]
    }
   ],
   "source": [
    "data = load('Backend/VGGFaceModelData/faceEmbeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print(f\"Dataset: train={trainX.shape[0], testX.shape[0]}\")\n",
    "#normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "save('Backend/VGGFaceModelData/classes.npy', out_encoder.classes_)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print(f\"Accuracy: train={score_train*100}, test={score_test*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43a2f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-713f43636006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'finalized_new_model.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Backend/VGGFaceModelData/{filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_new_model.sav'\n",
    "pickle.dump(model, open(f\"Backend/VGGFaceModelData/{filename}\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09003238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_new_model.sav'\n",
    "model1 = pickle.load(open(f\"Backend/VGGFaceModelData/{filename}\", 'rb'))\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = load('Backend/VGGFaceModelData/classes.npy')\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a51105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(filename, required_size=(224,224)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(img_rgb)\n",
    "    name = None\n",
    "    conf = 0.95\n",
    "    prob_= 50.00\n",
    "    for c, i in enumerate(_):\n",
    "        data = list()\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = asarray(f.resize(required_size))\n",
    "            data.append(get_embeddings(model, image))\n",
    "            data = asarray(data)\n",
    "            in_encoder = Normalizer(norm='l2')\n",
    "            dataX = in_encoder.transform(data)\n",
    "            class_ = model1.predict(dataX)\n",
    "            yhat_prob = model1.predict_proba(dataX)\n",
    "            predict_names = encoder.inverse_transform(class_)\n",
    "            prob = yhat_prob[0, class_]*100\n",
    "            if prob[0] > prob_:\n",
    "                print(prob[0], predict_names[0])\n",
    "                name = predict_names\n",
    "                cv2.putText(img, f'{name[0]}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('faces', img)\n",
    "    cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11715087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.79217058275164 Fouzan\n",
      "55.631202558490855 Ahmed Naeem\n",
      "55.62064912664858 ahmed\n"
     ]
    }
   ],
   "source": [
    "run(\"testing_data/friends.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a756de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "capture = cv2.VideoCapture(\"testing_data/\")\n",
    "frames_tracked = []\n",
    "\n",
    "while True:\n",
    "    IsTrue, frames = capture.read()\n",
    "    if frames is None:\n",
    "        break\n",
    "    img_cv2 = asarray(frames)\n",
    "    frames = Image.fromarray(cv2.cvtColor(frames, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(frames)\n",
    "    required_size=(224, 224)\n",
    "    name = None\n",
    "    conf = 0.90\n",
    "    prob_= 50.00\n",
    "    if _[0] is not None:\n",
    "        for c, i in enumerate(_):\n",
    "            data = list()\n",
    "            if i > conf:\n",
    "                box = boxes[c]\n",
    "                f = frames.crop((box[0], box[1], box[2], box[3]))\n",
    "                image = asarray(f.resize(required_size))\n",
    "                data.append(get_embeddings(model, image))\n",
    "                data = asarray(data)\n",
    "                in_encoder = Normalizer(norm='l2')\n",
    "                dataX = in_encoder.transform(data)\n",
    "                class_ = model1.predict(dataX)\n",
    "                yhat_prob = model1.predict_proba(dataX)\n",
    "                predict_names = encoder.inverse_transform(class_)\n",
    "                prob = yhat_prob[0, class_]*100\n",
    "                if prob[0] > prob_:\n",
    "                    name = predict_names\n",
    "                    x, y, w, h = math.floor(box[0]), math.floor(box[1]), abs(math.floor(box[0])-math.floor(box[2])), abs(math.floor(box[1])-math.floor(box[3]))\n",
    "                    cv2.putText(img_cv2, f'{name[0]}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "                    frame_draw = frames.copy()\n",
    "                    draw = ImageDraw.Draw(frame_draw)\n",
    "                    draw.text((box[0], box[1]), \"ahmed\", fill =\"blue\",align =\"right\") \n",
    "                    draw.rectangle(box.tolist(), outline=(255, 0, 0), width=1)\n",
    "                    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
    "    cv2.imshow('friends', img_cv2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "#     person_name, box_dimensions = face_recognize(frames)\n",
    "#     x,y,w,h = box_dimensions\n",
    "#     cv2.rectangle(frames,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#     cv2.putText(frames,person_name,(x+w+10,y+h),0,0.3,(0,255,0))\n",
    "#     image_lst.append(frames)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Convert to gif using the imageio.mimsave method\n",
    "# imageio.mimsave('ben_afflek_processed.gif', image_lst, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b90b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "    # calculate distance between embeddings\n",
    "    score = cosine(known_embedding, candidate_embedding)\n",
    "    if score <= thresh:\n",
    "        print('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
    "    else:\n",
    "        print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
    " \n",
    "# define filenames\n",
    "filenames = ['testing_data/ahmed_new.jpg', 'testing_data/ahmed1.1.jpeg', 'testing_data/fouz.jpeg', 'testing_data/fouzan.jpeg','testing_data/ahmed1.2.jpeg']\n",
    "# get embeddings file filenames\n",
    "embeddings = get_embeddings(filenames)\n",
    "print(embeddings[0].shape)\n",
    "print(embeddings[1].shape)\n",
    "# # define sharon stone\n",
    "# sharon_id = embeddings[0]\n",
    "# # verify known photos of sharon\n",
    "print('Positive Tests')\n",
    "is_match(embeddings[0], embeddings[4])\n",
    "# is_match(embeddings[0], embeddings[2])em\n",
    "# # verify known photos of other people\n",
    "print('Negative Tests')\n",
    "is_match(embeddings[0], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a213b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ed5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineDistance(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    " \n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "043626b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3954737186431885 Javeria Iftikhar\n",
      "0.3875473141670227 Javeria Iftikhar\n",
      "0.39362239837646484 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.386577308177948 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.39215368032455444 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3915807008743286 Javeria Iftikhar\n",
      "0.39799922704696655 Javeria Iftikhar\n",
      "0.38186126947402954 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3873748779296875 Javeria Iftikhar\n",
      "0.3866862654685974 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3948379158973694 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3940405249595642 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.38364917039871216 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3748490810394287 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.38149362802505493 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.38811129331588745 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3820524215698242 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39286506175994873 Javeria Iftikhar\n",
      "0.3895496129989624 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3939790725708008 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.39295005798339844 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.3896399140357971 Javeria Iftikhar\n",
      "0.39294642210006714 Javeria Iftikhar\n",
      "0.36964672803878784 Javeria Iftikhar\n",
      "0.38833510875701904 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.38854777812957764 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.39403223991394043 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.39239567518234253 Javeria Iftikhar\n",
      "0.38188880681991577 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3905062675476074 Javeria Iftikhar\n",
      "0.391745924949646 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.394253671169281 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3826996088027954 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.36533689498901367 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.37988197803497314 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3834012746810913 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.38523364067077637 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3867374658584595 Javeria Iftikhar\n",
      "0.39663177728652954 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.39322227239608765 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3937098979949951 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3879435658454895 Javeria Iftikhar\n",
      "0.3991214632987976 Javeria Iftikhar\n",
      "0.3915374279022217 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.397871732711792 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39780962467193604 Javeria Iftikhar\n",
      "0.3857279419898987 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3931947946548462 Javeria Iftikhar\n",
      "0.3939487338066101 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.39776480197906494 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3864172697067261 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.36957818269729614 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3816990852355957 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.38685619831085205 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.38848692178726196 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3899995684623718 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.39646631479263306 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3994012475013733 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n",
      "0.3913348317146301 Javeria Iftikhar\n"
     ]
    }
   ],
   "source": [
    "data = load('Backend/VGGFaceModelData/faceEmbeddings.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "capture = cv2.VideoCapture(\"\")\n",
    "frames_tracked = []\n",
    "diff = 0\n",
    "cosine_similarity = None\n",
    "new_trainX = list()\n",
    "for i in range(0, len(trainy)):\n",
    "    if trainy[i] == 'Javeria Iftikhar':\n",
    "        new_trainX.append(trainX[i])\n",
    "\n",
    "new_trainX = asarray(new_trainX)\n",
    "name = \"Javeria Iftikhar\"\n",
    "while True:\n",
    "    IsTrue, frames = capture.read()\n",
    "    if frames is None:\n",
    "        break\n",
    "#     frames = cv2.rotate(frames, cv2.ROTATE_180)\n",
    "    img_cv2 = asarray(frames)\n",
    "    frames = Image.fromarray(cv2.cvtColor(frames, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(frames)\n",
    "    required_size=(224,224)\n",
    "    conf = 0.50\n",
    "    prob_= 70.00\n",
    "    epsilon = 0.40\n",
    "    if _[0] is not None:\n",
    "        for c, i in enumerate(_):\n",
    "            if i > 0.70:\n",
    "                box = boxes[c]\n",
    "                f = frames.crop((box[0], box[1], box[2], box[3]))\n",
    "                image = f.resize(required_size)\n",
    "                data = get_embeddings(model, asarray(image))\n",
    "                for i, d in enumerate(trainX):\n",
    "                    diff = distance(data,d)\n",
    "                    name = trainy[i]\n",
    "                    cosine_similarity = findCosineDistance(data, d)\n",
    "                    x, y, w, h = math.floor(box[0]), math.floor(box[1]), abs(math.floor(box[0])-math.floor(box[2])), abs(math.floor(box[1])-math.floor(box[3]))\n",
    "                    cv2.rectangle(img_cv2, (x, y), (x+w, y+h), (255, 0, 0), thickness=1)\n",
    "                    \n",
    "                    if cosine_similarity <= epsilon:\n",
    "                        print(cosine_similarity, name)\n",
    "                        cv2.putText(img_cv2, f'{name}-{round(cosine_similarity,3)}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('friends', img_cv2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb4627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3468: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load('Backend/VGGFaceModelData/faceEmbeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "capture = cv2.VideoCapture(\"testing_data/R12NewVideo.mp4\")\n",
    "frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_index = frames-1\n",
    "diff = 0\n",
    "cosine_similarity = None\n",
    "\n",
    "while(frame_index!=0):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    IsTrue, frames = capture.read()\n",
    "    if frames is None:\n",
    "        break\n",
    "#     frames = cv2.rotate(frames, cv2.ROTATE_180)\n",
    "    img_cv2 = asarray(frames)\n",
    "    frames = Image.fromarray(cv2.cvtColor(frames, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(frames)\n",
    "    required_size=(224,224)\n",
    "    name = None\n",
    "    conf = 0.50\n",
    "    prob_= 70.00\n",
    "    epsilon = 0.34\n",
    "    frame_index = frame_index-1\n",
    "    if _[0] is not None:\n",
    "        for c, i in enumerate(_):\n",
    "            if i > 0.70:\n",
    "                box = boxes[c]\n",
    "                f = frames.crop((box[0], box[1], box[2], box[3]))\n",
    "                image = f.resize(required_size)\n",
    "                data = get_embeddings(model, asarray(image))\n",
    "                for i, d in enumerate(trainX):\n",
    "                    diff = distance(data,d)\n",
    "                    cosine_similarity = findCosineDistance(data, d)\n",
    "                    name = trainy[i]\n",
    "                    x, y, w, h = math.floor(box[0]), math.floor(box[1]), abs(math.floor(box[0])-math.floor(box[2])), abs(math.floor(box[1])-math.floor(box[3]))\n",
    "                    cv2.rectangle(img_cv2, (x, y), (x+w, y+h), (255, 0, 0), thickness=1)\n",
    "                    if cosine_similarity <= epsilon:\n",
    "                        print(cosine_similarity, name)\n",
    "                        cv2.putText(img_cv2, f'{name}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('friends', img_cv2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbc285",
   "metadata": {},
   "source": [
    "## Get Total Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2465b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "import os\n",
    "\n",
    "def get_duration(filename):\n",
    "\tclip = VideoFileClip(filename)\n",
    "\treturn clip.duration, clip.fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b62822b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"testing_data/DanishKhan.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79c01367",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration, fps = get_duration(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e051827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = duration * fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd7c6c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70654.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af058360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9\n",
      "17\n",
      "25\n",
      "33\n",
      "41\n",
      "49\n",
      "57\n",
      "65\n",
      "73\n",
      "81\n",
      "89\n",
      "97\n",
      "105\n",
      "113\n",
      "121\n",
      "129\n",
      "137\n",
      "145\n",
      "153\n",
      "161\n",
      "169\n",
      "177\n",
      "185\n",
      "193\n",
      "201\n",
      "209\n",
      "217\n",
      "225\n",
      "233\n",
      "241\n",
      "249\n",
      "257\n",
      "265\n",
      "273\n",
      "281\n",
      "289\n",
      "297\n",
      "305\n",
      "313\n",
      "321\n",
      "329\n",
      "337\n",
      "345\n",
      "353\n",
      "361\n",
      "369\n",
      "377\n",
      "385\n",
      "393\n",
      "401\n",
      "409\n",
      "417\n",
      "425\n",
      "433\n",
      "441\n",
      "449\n",
      "457\n",
      "465\n",
      "473\n",
      "481\n",
      "489\n",
      "497\n",
      "505\n",
      "513\n",
      "521\n",
      "529\n",
      "537\n",
      "545\n",
      "553\n",
      "561\n",
      "569\n",
      "577\n",
      "585\n",
      "593\n",
      "601\n",
      "609\n",
      "617\n",
      "625\n",
      "633\n",
      "641\n",
      "649\n",
      "657\n",
      "665\n",
      "673\n",
      "681\n",
      "689\n",
      "697\n",
      "705\n",
      "713\n",
      "721\n",
      "729\n",
      "737\n",
      "745\n",
      "753\n",
      "761\n",
      "769\n",
      "777\n",
      "785\n",
      "793\n",
      "801\n",
      "809\n",
      "817\n",
      "825\n",
      "833\n",
      "841\n",
      "849\n",
      "857\n",
      "865\n",
      "873\n",
      "881\n",
      "889\n",
      "897\n",
      "905\n",
      "913\n",
      "921\n",
      "929\n",
      "937\n",
      "945\n",
      "953\n",
      "961\n",
      "969\n",
      "977\n",
      "985\n",
      "993\n",
      "1001\n",
      "1009\n",
      "1017\n",
      "1025\n",
      "1033\n",
      "1041\n",
      "1049\n",
      "1057\n",
      "1065\n",
      "1073\n",
      "1081\n",
      "1089\n",
      "1097\n",
      "1105\n",
      "1113\n",
      "1121\n",
      "1129\n",
      "1137\n",
      "1145\n",
      "1153\n",
      "1161\n",
      "1169\n",
      "1177\n",
      "1185\n",
      "1193\n",
      "1201\n",
      "1209\n",
      "1217\n",
      "1225\n",
      "1233\n",
      "1241\n",
      "1249\n",
      "1257\n",
      "1265\n",
      "1273\n",
      "1281\n",
      "1289\n",
      "1297\n",
      "1305\n",
      "1313\n",
      "1321\n",
      "1329\n",
      "1337\n",
      "1345\n",
      "1353\n",
      "1361\n",
      "1369\n",
      "1377\n",
      "1385\n",
      "1393\n",
      "1401\n",
      "1409\n",
      "1417\n",
      "1425\n",
      "1433\n",
      "1441\n",
      "1449\n",
      "1457\n",
      "1465\n",
      "1473\n",
      "1481\n",
      "1489\n",
      "1497\n",
      "1505\n",
      "1513\n",
      "1521\n",
      "1529\n",
      "1537\n",
      "1545\n",
      "1553\n",
      "1561\n",
      "1569\n",
      "1577\n",
      "1585\n",
      "1593\n",
      "1601\n",
      "1609\n",
      "1617\n",
      "1625\n",
      "1633\n",
      "1641\n",
      "1649\n",
      "1657\n",
      "1665\n",
      "1673\n",
      "1681\n",
      "1689\n",
      "1697\n",
      "1705\n",
      "1713\n",
      "1721\n",
      "1729\n",
      "1737\n",
      "1745\n",
      "1753\n",
      "1761\n",
      "1769\n",
      "1777\n",
      "1785\n",
      "1793\n",
      "1801\n",
      "1809\n",
      "1817\n",
      "1825\n",
      "1833\n",
      "1841\n",
      "1849\n",
      "1857\n",
      "1865\n",
      "1873\n",
      "1881\n",
      "1889\n",
      "1897\n",
      "1905\n",
      "1913\n",
      "1921\n",
      "1929\n",
      "1937\n",
      "1945\n",
      "1953\n",
      "1961\n",
      "1969\n",
      "1977\n",
      "1985\n",
      "1993\n",
      "2001\n",
      "2009\n",
      "2017\n",
      "2025\n",
      "2033\n",
      "2041\n",
      "2049\n",
      "2057\n",
      "2065\n",
      "2073\n",
      "2081\n",
      "2089\n",
      "2097\n",
      "2105\n",
      "2113\n",
      "2121\n",
      "2129\n",
      "2137\n",
      "2145\n",
      "2153\n",
      "2161\n",
      "2169\n",
      "2177\n",
      "2185\n",
      "2193\n",
      "2201\n",
      "2209\n",
      "2217\n",
      "2225\n",
      "2233\n",
      "2241\n",
      "2249\n",
      "2257\n",
      "2265\n",
      "2273\n",
      "2281\n",
      "2289\n",
      "2297\n",
      "2305\n",
      "2313\n",
      "2321\n",
      "2329\n",
      "2337\n",
      "2345\n",
      "2353\n",
      "2361\n",
      "2369\n",
      "2377\n",
      "2385\n",
      "2393\n",
      "2401\n",
      "2409\n",
      "2417\n",
      "2425\n",
      "2433\n",
      "2441\n",
      "2449\n",
      "2457\n",
      "2465\n",
      "2473\n",
      "2481\n",
      "2489\n",
      "2497\n",
      "2505\n",
      "2513\n",
      "2521\n",
      "2529\n",
      "2537\n",
      "2545\n",
      "2553\n",
      "2561\n",
      "2569\n",
      "2577\n",
      "2585\n",
      "2593\n",
      "2601\n",
      "2609\n",
      "2617\n",
      "2625\n",
      "2633\n",
      "2641\n",
      "2649\n",
      "2657\n",
      "2665\n",
      "2673\n",
      "2681\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8e1d99277c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0mcosine_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindCosineDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-5c02639e7761>\u001b[0m in \u001b[0;36mfindCosineDistance\u001b[0;34m(source_representation, test_representation)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindCosineDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "\n",
    "data = load('VGGFaceModelData/faceEmbeddings_1.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "capture = cv2.VideoCapture(\"testing_data/DanishKhan.mp4\")\n",
    "frames = 0\n",
    "frame_index = 1\n",
    "diff = 0\n",
    "cosine_similarity = None\n",
    "\n",
    "while(frame_index<total_frames):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    IsTrue, frames = capture.read()\n",
    "    print(frame_index)\n",
    "    if frames is None:\n",
    "        break\n",
    "#     frames = cv2.rotate(frames, cv2.ROTATE_180)\n",
    "    img_cv2 = asarray(frames)\n",
    "    frames = Image.fromarray(cv2.cvtColor(frames, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(frames)\n",
    "    required_size=(224,224)\n",
    "    name = None\n",
    "    conf = 0.50\n",
    "    prob_= 70.00\n",
    "    epsilon = 0.34\n",
    "    frame_index = frame_index + 8\n",
    "    if _[0] is not None:\n",
    "        for c, i in enumerate(_):\n",
    "            if i > 0.90:\n",
    "                box = boxes[c]\n",
    "                f = frames.crop((box[0], box[1], box[2], box[3]))\n",
    "                image = f.resize(required_size)\n",
    "                data = get_embeddings(model, asarray(image))\n",
    "                for i, d in enumerate(trainX):\n",
    "                    diff = distance(data,d)\n",
    "                    cosine_similarity = findCosineDistance(data, d)\n",
    "                    name = trainy[i]\n",
    "                    x, y, w, h = math.floor(box[0]), math.floor(box[1]), abs(math.floor(box[0])-math.floor(box[2])), abs(math.floor(box[1])-math.floor(box[3]))\n",
    "                    cv2.rectangle(img_cv2, (x, y), (x+w, y+h), (255, 0, 0), thickness=1)\n",
    "                    if cosine_similarity <= epsilon:\n",
    "                        print(cosine_similarity, name)\n",
    "                        cv2.putText(img_cv2, f'{name}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('friends', img_cv2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b245b84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aashir', 'Abeer', 'Anam Qureshi', 'Anaum Hamid', 'Aqsa Zahid',\n",
       "       'Atiya', 'Bakhtawer', 'Basit Ali', 'Danish', 'Dr. Aqsa Aslam',\n",
       "       'Dr. Atif', 'Dr. Fahad Sherwani', 'Dr. Farooque',\n",
       "       'Dr. Farrukh Hassan', 'Dr. Farrukh Salim', 'Dr. Farrukh Shahid',\n",
       "       'Dr. Ghufran', 'Dr. Jawwad', 'Dr. Nadeem Kafi', 'Dr. Nausheen',\n",
       "       'Dr. Nouman', 'Dr. Rafi', 'Dr. Usama', 'Dr. Waheed',\n",
       "       'Dr. Zulfiqar', 'Erum', 'Fizza', 'Hajra', 'Hamza Ahmed', 'Hassan',\n",
       "       'Jamil', 'Javeria Iftikhar', 'Kashan', 'M. Shahzad', 'Mafaza',\n",
       "       'Musawar', 'Nida Munawar', 'Rabia Tabassum', 'Romasha', 'Safia',\n",
       "       'Shaharbano', 'Shahbaz', 'Shoaib Rauf', 'Sobia', 'Sohail', 'Zain',\n",
       "       'Zumar'], dtype='<U18')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load('VGGFaceModelData/faceEmbeddings_1.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "trainy = np.unique(trainy)\n",
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd927043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "17\n",
      "33\n",
      "0.3463847041130066 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.4471306800842285 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3276466131210327 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.3463847041130066 Dr. Atif\n",
      "0.34775543212890625 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3501056432723999 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.33057111501693726 Dr. Atif\n",
      "0.3545231819152832 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3463847041130066 Dr. Atif\n",
      "0.3276466131210327 Dr. Atif\n",
      "0.3276466131210327 Dr. Atif\n",
      "0.3463847041130066 Dr. Atif\n",
      "0.3463847041130066 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3440698981285095 Dr. Atif\n",
      "0.3303700089454651 Dr. Atif\n",
      "0.32960766553878784 Dr. Atif\n",
      "0.3340054154396057 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.3714192509651184 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.37500250339508057 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.36258041858673096 Dr. Atif\n",
      "0.3720017671585083 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.3720017671585083 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.38525599241256714 Dr. Atif\n",
      "0.37500250339508057 Dr. Atif\n",
      "0.3720017671585083 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.37500250339508057 Dr. Atif\n",
      "0.37500250339508057 Dr. Atif\n",
      "0.4073106050491333 Dr. Atif\n",
      "0.36620599031448364 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3720017671585083 Dr. Atif\n",
      "0.36896073818206787 Dr. Atif\n",
      "0.3809688687324524 Dr. Atif\n",
      "0.3784797787666321 Dr. Atif\n",
      "0.43871527910232544 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.44760048389434814 Dr. Atif\n",
      "0.4471306800842285 Dr. Atif\n",
      "0.43214738368988037 Dr. Atif\n",
      "0.44284284114837646 Dr. Atif\n",
      "0.42050743103027344 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4471306800842285 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.43214738368988037 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.4317553639411926 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.43214738368988037 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.43214738368988037 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.43260037899017334 Dr. Atif\n",
      "0.43214738368988037 Dr. Atif\n",
      "0.4174284338951111 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4469940662384033 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "0.4301775097846985 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.4301775097846985 Dr. Atif\n",
      "0.4301775097846985 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.4301775097846985 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.4319724440574646 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.4335583448410034 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "0.4301775097846985 Dr. Atif\n",
      "0.43563151359558105 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "0.44563376903533936 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.4261409640312195 Dr. Atif\n",
      "0.43538862466812134 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.437344491481781 Dr. Atif\n",
      "0.4316418170928955 Dr. Atif\n",
      "49\n",
      "0.4038485288619995 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.41123050451278687 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.3898785710334778 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.4038485288619995 Dr. Atif\n",
      "0.40291959047317505 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.404352068901062 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.3962392807006836 Dr. Atif\n",
      "0.40981125831604004 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4038485288619995 Dr. Atif\n",
      "0.3898785710334778 Dr. Atif\n",
      "0.3898785710334778 Dr. Atif\n",
      "0.4038485288619995 Dr. Atif\n",
      "0.4038485288619995 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.4027951955795288 Dr. Atif\n",
      "0.3951702117919922 Dr. Atif\n",
      "0.3950682282447815 Dr. Atif\n",
      "0.39669257402420044 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.3534178137779236 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.37480074167251587 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.34885549545288086 Dr. Atif\n",
      "0.3716246485710144 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.3716246485710144 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.39383530616760254 Dr. Atif\n",
      "0.37480074167251587 Dr. Atif\n",
      "0.3716246485710144 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.37480074167251587 Dr. Atif\n",
      "0.37480074167251587 Dr. Atif\n",
      "0.3798377513885498 Dr. Atif\n",
      "0.3668782114982605 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.3716246485710144 Dr. Atif\n",
      "0.3590572476387024 Dr. Atif\n",
      "0.3600385785102844 Dr. Atif\n",
      "0.35691720247268677 Dr. Atif\n",
      "0.43202197551727295 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.40081578493118286 Dr. Atif\n",
      "0.41123050451278687 Dr. Atif\n",
      "0.42766308784484863 Dr. Atif\n",
      "0.41064685583114624 Dr. Atif\n",
      "0.41821080446243286 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.41123050451278687 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.42766308784484863 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.42657262086868286 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.42766308784484863 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.42766308784484863 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.42608344554901123 Dr. Atif\n",
      "0.42766308784484863 Dr. Atif\n",
      "0.413346529006958 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "0.4087800979614258 Dr. Atif\n",
      "65\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44931167364120483 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44446951150894165 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.431898295879364 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.4485968351364136 Dr. Atif\n",
      "0.44523316621780396 Dr. Atif\n",
      "0.44560885429382324 Dr. Atif\n",
      "0.41144323348999023 Dr. Atif\n",
      "0.44931167364120483 Dr. Atif\n",
      "0.44552165269851685 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.44931167364120483 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4396020174026489 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "0.4469366669654846 Dr. Atif\n",
      "81\n",
      "0.4306783080101013 Dr. Atif\n",
      "0.4430914521217346 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.3858596682548523 Dr. Atif\n",
      "0.4306783080101013 Dr. Atif\n",
      "0.4344596862792969 Dr. Atif\n",
      "0.42272692918777466 Dr. Atif\n",
      "0.4146740436553955 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4306783080101013 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4344596862792969 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.43369060754776 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4344596862792969 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.4344596862792969 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.4340451955795288 Dr. Atif\n",
      "0.4344596862792969 Dr. Atif\n",
      "0.39652514457702637 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "0.4296914339065552 Dr. Atif\n",
      "97\n",
      "113\n",
      "129\n",
      "145\n",
      "161\n",
      "177\n",
      "193\n",
      "209\n",
      "225\n",
      "241\n",
      "257\n",
      "273\n",
      "289\n",
      "305\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.4423191547393799 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.4413861632347107 Dr. Atif\n",
      "0.44639086723327637 Dr. Atif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "337\n",
      "353\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.40821176767349243 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.43033552169799805 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.431532621383667 Dr. Atif\n",
      "0.4319767951965332 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.4319767951965332 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.41053658723831177 Dr. Atif\n",
      "0.43033552169799805 Dr. Atif\n",
      "0.4319767951965332 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.43033552169799805 Dr. Atif\n",
      "0.43033552169799805 Dr. Atif\n",
      "0.3851557970046997 Dr. Atif\n",
      "0.43040984869003296 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.4319767951965332 Dr. Atif\n",
      "0.44549840688705444 Dr. Atif\n",
      "0.40441691875457764 Dr. Atif\n",
      "0.4081938862800598 Dr. Atif\n",
      "0.43728840351104736 Dr. Atif\n",
      "369\n",
      "385\n",
      "401\n",
      "417\n",
      "433\n",
      "449\n",
      "465\n",
      "481\n",
      "497\n",
      "513\n",
      "529\n",
      "545\n",
      "561\n",
      "577\n",
      "593\n",
      "609\n",
      "625\n",
      "641\n",
      "657\n",
      "673\n",
      "689\n",
      "705\n",
      "721\n",
      "737\n",
      "753\n",
      "769\n",
      "785\n",
      "801\n",
      "817\n",
      "833\n",
      "849\n",
      "865\n",
      "881\n",
      "897\n",
      "913\n",
      "929\n",
      "945\n",
      "961\n",
      "977\n",
      "993\n",
      "1009\n",
      "1025\n",
      "1041\n",
      "1057\n",
      "1073\n",
      "1089\n",
      "1105\n",
      "1121\n",
      "1137\n",
      "1153\n",
      "1169\n",
      "1185\n",
      "1201\n",
      "1217\n",
      "1233\n",
      "1249\n",
      "1265\n",
      "1281\n",
      "1297\n",
      "1313\n",
      "1329\n",
      "1345\n",
      "1361\n",
      "1377\n",
      "1393\n",
      "1409\n",
      "1425\n",
      "1441\n",
      "1457\n",
      "1473\n",
      "1489\n",
      "1505\n",
      "1521\n",
      "1537\n",
      "1553\n",
      "1569\n",
      "1585\n",
      "1601\n",
      "1617\n",
      "1633\n",
      "1649\n",
      "1665\n",
      "1681\n",
      "1697\n",
      "1713\n",
      "1729\n",
      "1745\n",
      "1761\n",
      "1777\n",
      "1793\n",
      "1809\n",
      "1825\n",
      "1841\n",
      "1857\n",
      "1873\n",
      "1889\n",
      "1905\n",
      "0.43200767040252686 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.3751668930053711 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4378257393836975 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.43200767040252686 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.43026912212371826 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.44399672746658325 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.43200767040252686 Dr. Atif\n",
      "0.4378257393836975 Dr. Atif\n",
      "0.4378257393836975 Dr. Atif\n",
      "0.43200767040252686 Dr. Atif\n",
      "0.43200767040252686 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4302254915237427 Dr. Atif\n",
      "0.42735594511032104 Dr. Atif\n",
      "0.4437282085418701 Dr. Atif\n",
      "0.4233020544052124 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.3781229853630066 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.4060247540473938 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.3631918430328369 Dr. Atif\n",
      "0.40227586030960083 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.40227586030960083 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.4247332215309143 Dr. Atif\n",
      "0.4060247540473938 Dr. Atif\n",
      "0.40227586030960083 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.4060247540473938 Dr. Atif\n",
      "0.4060247540473938 Dr. Atif\n",
      "0.41259950399398804 Dr. Atif\n",
      "0.39987558126449585 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.40227586030960083 Dr. Atif\n",
      "0.3756241202354431 Dr. Atif\n",
      "0.38689881563186646 Dr. Atif\n",
      "0.3832249045372009 Dr. Atif\n",
      "0.38182663917541504 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.32534176111221313 Dr. Atif\n",
      "0.3751668930053711 Dr. Atif\n",
      "0.3718039393424988 Dr. Atif\n",
      "0.36643749475479126 Dr. Atif\n",
      "0.35525643825531006 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3751668930053711 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3718039393424988 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.37027156352996826 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3718039393424988 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.3718039393424988 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.3689876198768616 Dr. Atif\n",
      "0.3718039393424988 Dr. Atif\n",
      "0.34149670600891113 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "0.3721833825111389 Dr. Atif\n",
      "1921\n",
      "1937\n",
      "1953\n",
      "1969\n",
      "1985\n",
      "0.4151841998100281 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3305780291557312 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.4156322479248047 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.4151841998100281 Dr. Atif\n",
      "0.4195919632911682 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.4200674295425415 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.4199557900428772 Dr. Atif\n",
      "0.4175646901130676 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.4151841998100281 Dr. Atif\n",
      "0.4156322479248047 Dr. Atif\n",
      "0.4156322479248047 Dr. Atif\n",
      "0.4151841998100281 Dr. Atif\n",
      "0.4151841998100281 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40950411558151245 Dr. Atif\n",
      "0.412276029586792 Dr. Atif\n",
      "0.4195464849472046 Dr. Atif\n",
      "0.40904879570007324 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3487533926963806 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3763692378997803 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.34494131803512573 Dr. Atif\n",
      "0.3728939890861511 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3728939890861511 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.37028342485427856 Dr. Atif\n",
      "0.3763692378997803 Dr. Atif\n",
      "0.3728939890861511 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.3763692378997803 Dr. Atif\n",
      "0.3763692378997803 Dr. Atif\n",
      "0.36431002616882324 Dr. Atif\n",
      "0.3701730966567993 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3728939890861511 Dr. Atif\n",
      "0.3612484335899353 Dr. Atif\n",
      "0.3568102717399597 Dr. Atif\n",
      "0.3541579842567444 Dr. Atif\n",
      "0.34283483028411865 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.2784563899040222 Dr. Atif\n",
      "0.3305780291557312 Dr. Atif\n",
      "0.3404998779296875 Dr. Atif\n",
      "0.3229791522026062 Dr. Atif\n",
      "0.3183990716934204 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3305780291557312 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3404998779296875 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.33885443210601807 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3404998779296875 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.3404998779296875 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.33644115924835205 Dr. Atif\n",
      "0.3404998779296875 Dr. Atif\n",
      "0.30119097232818604 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "0.3276113271713257 Dr. Atif\n",
      "2001\n",
      "2017\n",
      "2033\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.41045814752578735 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.42100101709365845 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.39649349451065063 Dr. Atif\n",
      "0.42291611433029175 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.42291611433029175 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.4260239005088806 Dr. Atif\n",
      "0.42100101709365845 Dr. Atif\n",
      "0.42291611433029175 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "0.42100101709365845 Dr. Atif\n",
      "0.42100101709365845 Dr. Atif\n",
      "0.41695183515548706 Dr. Atif\n",
      "0.42085713148117065 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.42291611433029175 Dr. Atif\n",
      "0.41167348623275757 Dr. Atif\n",
      "0.41170036792755127 Dr. Atif\n",
      "0.4133948087692261 Dr. Atif\n",
      "2049\n",
      "0.41510069370269775 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.3905424475669861 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.41510069370269775 Dr. Atif\n",
      "0.40169161558151245 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.4193248748779297 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.3944113850593567 Dr. Atif\n",
      "0.41832345724105835 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.41510069370269775 Dr. Atif\n",
      "0.3905424475669861 Dr. Atif\n",
      "0.3905424475669861 Dr. Atif\n",
      "0.41510069370269775 Dr. Atif\n",
      "0.41510069370269775 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.40974724292755127 Dr. Atif\n",
      "0.38791364431381226 Dr. Atif\n",
      "0.3940608501434326 Dr. Atif\n",
      "0.3859725594520569 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.35273098945617676 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.36708003282546997 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.34459394216537476 Dr. Atif\n",
      "0.3684808611869812 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.3684808611869812 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.3746991753578186 Dr. Atif\n",
      "0.36708003282546997 Dr. Atif\n",
      "0.3684808611869812 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.36708003282546997 Dr. Atif\n",
      "0.36708003282546997 Dr. Atif\n",
      "0.3755960464477539 Dr. Atif\n",
      "0.3670060634613037 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3684808611869812 Dr. Atif\n",
      "0.3543550372123718 Dr. Atif\n",
      "0.3557314872741699 Dr. Atif\n",
      "0.3566591143608093 Dr. Atif\n",
      "0.41437065601348877 Dr. Atif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065\n",
      "0.44071775674819946 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.37915700674057007 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44071775674819946 Dr. Atif\n",
      "0.4421873688697815 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44071775674819946 Dr. Atif\n",
      "0.44071775674819946 Dr. Atif\n",
      "0.44071775674819946 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.44004499912261963 Dr. Atif\n",
      "0.4387716054916382 Dr. Atif\n",
      "0.43900513648986816 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.3608730435371399 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.3885957598686218 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.34666502475738525 Dr. Atif\n",
      "0.38714754581451416 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.38714754581451416 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.4131554961204529 Dr. Atif\n",
      "0.3885957598686218 Dr. Atif\n",
      "0.38714754581451416 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.3885957598686218 Dr. Atif\n",
      "0.3885957598686218 Dr. Atif\n",
      "0.3965322971343994 Dr. Atif\n",
      "0.38452601432800293 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.38714754581451416 Dr. Atif\n",
      "0.35620248317718506 Dr. Atif\n",
      "0.36991286277770996 Dr. Atif\n",
      "0.36900418996810913 Dr. Atif\n",
      "0.4068080186843872 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.35031282901763916 Dr. Atif\n",
      "0.37915700674057007 Dr. Atif\n",
      "0.4001866579055786 Dr. Atif\n",
      "0.3752526044845581 Dr. Atif\n",
      "0.389431893825531 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.37915700674057007 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.4001866579055786 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.39978939294815063 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.4001866579055786 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.4001866579055786 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.39821577072143555 Dr. Atif\n",
      "0.4001866579055786 Dr. Atif\n",
      "0.37575972080230713 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "0.3784502148628235 Dr. Atif\n",
      "2081\n",
      "2097\n",
      "2113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-44007a7a7fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mrequired_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             )\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MTCNN batch processing only compatible with equal-dimension images.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MTCNN batch processing only compatible with equal-dimension images.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/friv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0m__array_interface__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArrayData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "\n",
    "data = load('VGGFaceModelData/faceEmbeddings_1.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "capture = cv2.VideoCapture(\"testing_data/AtifTahir.mp4\")\n",
    "frames = 0\n",
    "frame_index = 1\n",
    "diff = 0\n",
    "cosine_similarity = None\n",
    "new_trainX = list()\n",
    "for i in range(0, len(trainy)):\n",
    "    if trainy[i] == 'Dr. Atif':\n",
    "        new_trainX.append(trainX[i])\n",
    "\n",
    "new_trainX = asarray(new_trainX)\n",
    "name = \"Dr. Atif\"\n",
    "\n",
    "while(frame_index<total_frames):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    IsTrue, frames = capture.read()\n",
    "    print(frame_index)\n",
    "    if frames is None:\n",
    "        break\n",
    "#     frames = cv2.rotate(frames, cv2.ROTATE_180)\n",
    "    img_cv2 = asarray(frames)\n",
    "    frames = cv2.cvtColor(frames, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    frames = Image.fromarray(frames)\n",
    "    boxes, _ = mtcn.detect(frames)\n",
    "    required_size=(224,224)\n",
    "    name = None\n",
    "    conf = 0.50\n",
    "    prob_= 70.00\n",
    "    epsilon = 0.45\n",
    "    frame_index = frame_index + 16\n",
    "    if _[0] is not None:\n",
    "        for c, i in enumerate(_):\n",
    "            if i > 0.70:\n",
    "                box = boxes[c]\n",
    "                f = frames.crop((box[0], box[1], box[2], box[3]))\n",
    "                image = f.resize(required_size)\n",
    "                data = get_embeddings(model, asarray(image))\n",
    "                for i, d in enumerate(new_trainX):\n",
    "                    name = \"Dr. Atif\"\n",
    "                    cosine_similarity = findCosineDistance(data, d)\n",
    "                    x, y, w, h = math.floor(box[0]), math.floor(box[1]), abs(math.floor(box[0])-math.floor(box[2])), abs(math.floor(box[1])-math.floor(box[3]))\n",
    "                    cv2.rectangle(img_cv2, (x, y), (x+w, y+h), (255, 0, 0), thickness=1)\n",
    "                    if cosine_similarity <= epsilon:\n",
    "                        print(cosine_similarity, name)\n",
    "                        cv2.putText(img_cv2, f'{name}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('friends', img_cv2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cc1c7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3468: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fouzanasif/miniconda3/envs/friv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "489 1124\n",
      "977 1092\n",
      "1465 1172\n",
      "1953 1224\n",
      "2441 1168\n",
      "2665 504\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import imageio\n",
    "\n",
    "from random import randint\n",
    "\n",
    "\n",
    "data = load('VGGFaceModelData/faceEmbeddings_1.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "capture = cv2.VideoCapture(\"testing_data/mm.mp4\")\n",
    "frames = 0\n",
    "frame_index = 1\n",
    "diff = 0\n",
    "cosine_similarity = None\n",
    "new_trainX = list()\n",
    "for i in range(0, len(trainy)):\n",
    "    if trainy[i] == 'Dr. Rafi':\n",
    "        new_trainX.append(trainX[i])\n",
    "\n",
    "new_trainX = asarray(new_trainX)\n",
    "name = \"Dr. Rafi\"\n",
    "framess = []\n",
    "faces = []\n",
    "data1 = []\n",
    "while(frame_index<int(total_frames)):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    IsTrue, frames = capture.read()\n",
    "    frame_index = frame_index + 8\n",
    "    if len(framess) >= 60 or frames is None:\n",
    "#         resize = 0.5\n",
    "#         framess = [cv2.resize(f, (int(f.shape[1] * resize), int(f.shape[0] * resize))) for f in framess]\n",
    "\n",
    "        boxes, _ = mtcn.detect(framess[::4])\n",
    "        required_size=(224,224)\n",
    "        name = None\n",
    "        conf = 0.50\n",
    "        prob_= 70.00\n",
    "        epsilon = 0.45\n",
    "        for i, frame in enumerate(framess):\n",
    "            box_ind = int(i / 4)\n",
    "            if boxes[box_ind] is None:\n",
    "                continue\n",
    "            for ind,box in enumerate(boxes[box_ind]):\n",
    "                if _[box_ind][ind] > 0.90:\n",
    "                    img_cv2 = asarray(frame)\n",
    "                    frame = Image.fromarray(img_cv2)\n",
    "                    f = frame.crop((box[0], box[1], box[2], box[3]))\n",
    "                    faces.append(f)\n",
    "#                     image = f.resize(required_size)\n",
    "#                     data1.append(get_embeddings(model, asarray(image)))\n",
    "#                     print(i)\n",
    "#                     name = \"Dr. Rafi\"\n",
    "#                     cosine_similarity = findCosineDistance(data, new_trainX[0])  \n",
    "#                     if cosine_similarity <= epsilon:\n",
    "#                         print(cosine_similarity, name)\n",
    "        print(frame_index, len(faces))\n",
    "        framess = []\n",
    "        faces = []\n",
    "    else:\n",
    "        frames = cv2.cvtColor(frames, cv2.COLOR_BGR2RGB)\n",
    "        framess.append(frames)\n",
    "\n",
    "capture.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04601bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
