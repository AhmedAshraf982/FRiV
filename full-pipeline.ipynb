{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ed5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import asarray, savez_compressed, load, expand_dims, save\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "import os \n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "from keras.models import load_model\n",
    "import mtcnn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3070abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160,160)):\n",
    "    # load image from file\n",
    "    image = cv2.imread(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector using default weights\n",
    "    detector = mtcnn.MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    face_array = []\n",
    "    # extract the bounding box from the first face\n",
    "    for res in results:\n",
    "        x1, y1, width, height = res['box']\n",
    "        # confidence\n",
    "        confidence = res['confidence']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1+width, y1+height\n",
    "        # greater than 0.95\n",
    "        if confidence > 0.85:\n",
    "            # extract the face\n",
    "            face = pixels[y1:y2, x1:x2]\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df8166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e183123",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcn = MTCNN(margin=20, post_process=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c172d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fast_face(filename, required_size=(160,160)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pixels = asarray(img_rgb)\n",
    "    boxes, _ = mtcn.detect(pixels)\n",
    "    face_array = []\n",
    "    for c, i in enumerate(_):\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = f.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3654a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    #enumerate files\n",
    "    for filename in os.listdir(directory):\n",
    "        # path\n",
    "        path = os.path.join(directory, filename)\n",
    "        # get face\n",
    "        face = extract_fast_face(path)\n",
    "        # append all faces in an image into new faces array\n",
    "        for pixel in face:\n",
    "            faces.append(pixel)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "568f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset that contains one subdir  for each class that in turn contains images\n",
    "def load_dataset(dir_):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in os.listdir(dir_):\n",
    "        # path\n",
    "        path = os.path.join(dir_, subdir)\n",
    "        # skip any files that might be in the dir\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels \n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print(f\"loaded {len(faces)} examples for class {subdir}\")\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db15b17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 26 examples for class Abdul Rehman\n",
      "loaded 14 examples for class ahmed\n",
      "loaded 14 examples for class ben_afflek\n",
      "loaded 18 examples for class elton_john\n",
      "loaded 13 examples for class Fouzan\n",
      "loaded 22 examples for class jerry_seinfeld\n",
      "loaded 17 examples for class madonna\n",
      "loaded 22 examples for class mindy_kaling\n",
      "loaded 14 examples for class Mohib Rehman\n",
      "loaded 12 examples for class Shayan\n",
      "(172, 160, 160, 3) (172,)\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "trainX, trainy = load_dataset(\"data/train\")\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff3c7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 5 examples for class Abdul Rehman\n",
      "loaded 11 examples for class ahmed\n",
      "loaded 5 examples for class ben_afflek\n",
      "loaded 4 examples for class elton_john\n",
      "loaded 11 examples for class Fouzan\n",
      "loaded 7 examples for class jerry_seinfeld\n",
      "loaded 5 examples for class madonna\n",
      "loaded 5 examples for class mindy_kaling\n",
      "loaded 4 examples for class Mohib Rehman\n"
     ]
    }
   ],
   "source": [
    "testX, testy = load_dataset(\"data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't run this\n",
    "transform = alb.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Rotate(),\n",
    "    A.Flip(),\n",
    "    A.Transpose(),\n",
    "    A.OneOf([\n",
    "            A.MotionBlur(p=0.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb591d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('data.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "05305b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't run this\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f331a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't run this\n",
    "faces = load_faces(\"data/train/ahmed\")\n",
    "# make subplot setup\n",
    "new_faces = faces\n",
    "print(len(new_faces))\n",
    "for face in faces:\n",
    "    for i in range(10):\n",
    "        transformed = transform(image=face)\n",
    "        new_faces.append(transformed['image'])\n",
    "\n",
    "len(new_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4891fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:118: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "[<tf.Tensor 'input_1_1:0' shape=(?, 160, 160, 3) dtype=float32>]\n",
      "[<tf.Tensor 'Bottleneck_BatchNorm/cond/Merge:0' shape=(?, 128) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dad5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    #standardize pixel values across channesl (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels-mean)/std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e707477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ((172, 160, 160, 3), (172,), (57, 160, 160, 3), (57,))\n",
      "(172, 128)\n",
      "(57, 128)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "data = load('data.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print(f\"Loaded: {trainX.shape, trainy.shape, testX.shape, testy.shape}\")\n",
    "# load the facenet model\n",
    "model = load_model('facenet_keras.h5')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embedding(model,face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    embedding = get_embedding(model,face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d26d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('face_embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d225b4b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=(172, 57)\n",
      "Accuracy: train=99.4186046511628, test=94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "data = load('face_embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print(f\"Dataset: train={trainX.shape[0], testX.shape[0]}\")\n",
    "#normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "save('classes.npy', out_encoder.classes_)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print(f\"Accuracy: train={score_train*100}, test={score_test*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3d92792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([79.61936087]),\n",
       " 7,\n",
       " array([[0.02478102, 0.00590421, 0.00998395, 0.0246111 , 0.01115612,\n",
       "         0.02649236, 0.06365266, 0.79619361, 0.02076394, 0.01646104]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "class_ = loaded_model.predict([trainX[95]])\n",
    "yhat_prob = loaded_model.predict_proba([trainX[95]])\n",
    "cl = class_[0]\n",
    "cla_prob = yhat_prob[0, class_]*100\n",
    "cla_prob, cl, yhat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d11f8d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,\n",
       "       6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 7, 7, 7, 7, 7, 8,\n",
       "       8, 8, 8, 8, 9, 9, 9, 9, 9, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "660a120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,\n",
       "       6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 7, 7, 3, 3, 7, 8,\n",
       "       8, 8, 8, 8, 9, 9, 9, 9, 9, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef5c1d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67423788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test == testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc6ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "{'box': [264, 491, 36, 54], 'confidence': 0.9554527997970581, 'keypoints': {'left_eye': (287, 510), 'right_eye': (298, 510), 'nose': (301, 521), 'mouth_left': (287, 532), 'mouth_right': (295, 532)}}\n"
     ]
    }
   ],
   "source": [
    "pixels = extract_face('testing_data/ahmed.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26858131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:118: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('facenet_keras.h5')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "# for face_pixels in pixels:\n",
    "embedding = get_embedding(model1,pixels[0])\n",
    "newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63ee08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(newTrainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ab1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ahmed'], dtype='<U14')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "class_ = loaded_model.predict(trainX)\n",
    "yhat_prob = loaded_model.predict_proba(trainX)\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = load('classes.npy')\n",
    "predict_names = encoder.inverse_transform(class_)\n",
    "cl = class_[0]\n",
    "cla_prob = yhat_prob[0, class_]*100\n",
    "predict_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d4b7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = load('classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "724c7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "face_embedded_model = load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1ab6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(filename, required_size=(160,160)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(img_rgb)\n",
    "    name = None\n",
    "    conf = 0.95\n",
    "    prob_=20.00\n",
    "    data = list()\n",
    "    for c, i in enumerate(_):\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = f.resize(required_size)\n",
    "            data.append(get_embedding(face_embedded_model, asarray(image)))\n",
    "            data = asarray(data)\n",
    "            in_encoder = Normalizer(norm='l2')\n",
    "            dataX = in_encoder.transform(data)\n",
    "            class_ = model.predict(dataX)\n",
    "            yhat_prob = model.predict_proba(dataX)\n",
    "            predict_names = encoder.inverse_transform(class_)\n",
    "            prob = yhat_prob[0, class_]*100\n",
    "            print(prob)\n",
    "            print(predict_names)\n",
    "            if prob[0] > prob_:\n",
    "                print(prob[0])\n",
    "                name = predict_names\n",
    "                print(name)\n",
    "                cv2.putText(img_rgb, f'{name}', (box[0], box[2]), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "                cv2.imshow('faces', img_rgb)\n",
    "                cv2.waitKey(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c520eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.67120718]\n",
      "['ahmed']\n",
      "61.67120718034897\n",
      "['ahmed']\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-fb8321e1c060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testing_data/ahmed1.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-78-2f031545e458>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(filename, required_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{name}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_ITALIC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'faces'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "run(\"testing_data/ahmed1.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61430420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DON'T RUN THIS\n",
    "pixels = extract_face('data/train/ahmed/IMG_20210828_100731.jpg')\n",
    "len(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4bee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this for visualization only\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "for pixel in pixels:\n",
    "    fig.add_subplot(1,1,i)\n",
    "    plt.imshow(pixel)\n",
    "    plt.axis('off')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't run this\n",
    "img = cv2.imread(\"data/train/ahmed/IMG_20210828_100731.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
