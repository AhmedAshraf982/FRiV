{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb33dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import cv2\n",
    "from numpy import asarray, savez_compressed, load, expand_dims, save,array\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b95186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(224,224)):\n",
    "    # load image from file\n",
    "    image = cv2.imread(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector using default weights\n",
    "    detector = mtcnn.MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    face_array = []\n",
    "    # extract the bounding box from the first face\n",
    "    for res in results:\n",
    "        x1, y1, width, height = res['box']\n",
    "        # confidence\n",
    "        confidence = res['confidence']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1+width, y1+height\n",
    "        # greater than 0.95\n",
    "        if confidence > 0.85:\n",
    "            # extract the face\n",
    "            face = pixels[y1:y2, x1:x2]\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f6533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fb79d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcn = MTCNN(margin=20, post_process=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2636193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fast_face(filename, required_size=(224,224)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pixels = asarray(img_rgb)\n",
    "    boxes, _ = mtcn.detect(pixels)\n",
    "    face_array = []\n",
    "    for c, i in enumerate(_):\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = f.resize(required_size)\n",
    "            face_array.append(asarray(image))\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2575f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    #enumerate files\n",
    "    for filename in os.listdir(directory):\n",
    "        # path\n",
    "        path = os.path.join(directory, filename)\n",
    "        # get face\n",
    "        face = extract_fast_face(path)\n",
    "        # append all faces in an image into new faces array\n",
    "        for pixel in face:\n",
    "            faces.append(pixel)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04c70986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset that contains one subdir  for each class that in turn contains images\n",
    "def load_dataset(dir_):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in os.listdir(dir_):\n",
    "        # path\n",
    "        path = os.path.join(dir_, subdir)\n",
    "        # skip any files that might be in the dir\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels \n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print(f\"loaded {len(faces)} examples for class {subdir}\")\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66ee3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 26 examples for class Abdul Rehman\n",
      "loaded 14 examples for class ahmed\n",
      "loaded 14 examples for class Ahmed Naeem\n",
      "loaded 14 examples for class ben_afflek\n",
      "loaded 18 examples for class elton_john\n",
      "loaded 13 examples for class Fouzan\n",
      "loaded 25 examples for class Hassan Qureshi\n",
      "loaded 22 examples for class jerry_seinfeld\n",
      "loaded 17 examples for class madonna\n",
      "loaded 22 examples for class mindy_kaling\n",
      "loaded 14 examples for class Mohib Rehman\n",
      "loaded 10 examples for class Shayan\n",
      "loaded 7 examples for class Sumair\n",
      "loaded 29 examples for class Zulfiqar\n",
      "(245, 224, 224, 3) (245,)\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "trainX, trainy = load_dataset(\"data/train\")\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ce73f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 5 examples for class Abdul Rehman\n",
      "loaded 11 examples for class ahmed\n",
      "loaded 7 examples for class Ahmed Naeem\n",
      "loaded 5 examples for class ben_afflek\n",
      "loaded 4 examples for class elton_john\n",
      "loaded 11 examples for class Fouzan\n",
      "loaded 5 examples for class Hassan Qureshi\n",
      "loaded 7 examples for class jerry_seinfeld\n",
      "loaded 5 examples for class madonna\n",
      "loaded 5 examples for class mindy_kaling\n",
      "loaded 4 examples for class Mohib Rehman\n",
      "loaded 2 examples for class Shayan\n",
      "loaded 3 examples for class Sumair\n",
      "loaded 7 examples for class Zulfiqar\n"
     ]
    }
   ],
   "source": [
    "testX, testy = load_dataset(\"data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f64b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('new_data.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34644f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract faces and calculate face embeddings for a list of photo files\n",
    "def get_embeddings(model,faces):\n",
    "    # convert into an array of samples\n",
    "    samples = faces.astype('float32')\n",
    "    samples = expand_dims(samples, axis=0)\n",
    "    # prepare the face for the model, e.g. center pixels\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "    # perform prediction\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6699375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ((245, 224, 224, 3), (245,), (81, 224, 224, 3), (81,))\n",
      "(224, 224, 3)\n",
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "data = load('new_data.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print(f\"Loaded: {trainX.shape, trainy.shape, testX.shape, testy.shape}\")\n",
    "# load the facenet model\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embeddings(model,face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    break\n",
    "    embedding = get_embeddings(model,face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d237fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('face_embeddings_new.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c2bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=(245, 81)\n",
      "Accuracy: train=99.59183673469387, test=95.06172839506173\n"
     ]
    }
   ],
   "source": [
    "data = load('face_embeddings_new.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print(f\"Dataset: train={trainX.shape[0], testX.shape[0]}\")\n",
    "#normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "save('classes_new.npy', out_encoder.classes_)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print(f\"Accuracy: train={score_train*100}, test={score_test*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43a2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_new_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09003238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3468: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programming\\ML\\FYP_PROJECT\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_new_model.sav'\n",
    "model1 = pickle.load(open(filename, 'rb'))\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = load('classes_new.npy')\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95a51105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(filename, required_size=(224,224)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_rgb = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcn.detect(img_rgb)\n",
    "    name = None\n",
    "    conf = 0.95\n",
    "    prob_= 35.00\n",
    "    for c, i in enumerate(_):\n",
    "        data = list()\n",
    "        if i > 0.95:\n",
    "            box = boxes[c]\n",
    "            f = img_rgb.crop((box[0], box[1], box[2], box[3]))\n",
    "            image = asarray(f.resize(required_size))\n",
    "            data.append(get_embeddings(model, image))\n",
    "            data = asarray(data)\n",
    "            in_encoder = Normalizer(norm='l2')\n",
    "            dataX = in_encoder.transform(data)\n",
    "            class_ = model1.predict(dataX)\n",
    "            yhat_prob = model1.predict_proba(dataX)\n",
    "            predict_names = encoder.inverse_transform(class_)\n",
    "            prob = yhat_prob[0, class_]*100\n",
    "            if prob[0] > prob_:\n",
    "                print(prob[0], predict_names[0])\n",
    "                name = predict_names\n",
    "                cv2.putText(img, f'{name[0]}', (int(box[0]), int(box[1])), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n",
    "    cv2.imshow('faces', img)\n",
    "    cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfaa3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"testing_data/ahmed1.1.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b90b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [587, 280, 221, 286], 'confidence': 1.0, 'keypoints': {'left_eye': (666, 384), 'right_eye': (767, 387), 'nose': (726, 441), 'mouth_left': (674, 497), 'mouth_right': (760, 498)}}]\n",
      "[{'box': [504, 697, 169, 298], 'confidence': 0.9475782513618469, 'keypoints': {'left_eye': (621, 822), 'right_eye': (671, 817), 'nose': (670, 888), 'mouth_left': (609, 943), 'mouth_right': (645, 940)}}]\n",
      "[{'box': [47, 32, 43, 48], 'confidence': 0.9989558458328247, 'keypoints': {'left_eye': (61, 53), 'right_eye': (81, 52), 'nose': (72, 63), 'mouth_left': (63, 71), 'mouth_right': (81, 71)}}]\n",
      "[{'box': [357, 71, 112, 137], 'confidence': 1.0, 'keypoints': {'left_eye': (389, 123), 'right_eye': (443, 123), 'nose': (415, 147), 'mouth_left': (390, 173), 'mouth_right': (438, 174)}}]\n",
      "[{'box': [31, 67, 36, 39], 'confidence': 0.9999871253967285, 'keypoints': {'left_eye': (43, 82), 'right_eye': (60, 79), 'nose': (54, 91), 'mouth_left': (46, 98), 'mouth_right': (62, 96)}}]\n",
      "(2048,)\n",
      "(2048,)\n",
      "Positive Tests\n",
      ">face is NOT a Match (0.535 > 0.500)\n",
      "Negative Tests\n",
      ">face is NOT a Match (0.610 > 0.500)\n"
     ]
    }
   ],
   "source": [
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "    # calculate distance between embeddings\n",
    "    score = cosine(known_embedding, candidate_embedding)\n",
    "    if score <= thresh:\n",
    "        print('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
    "    else:\n",
    "        print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
    " \n",
    "# define filenames\n",
    "filenames = ['testing_data/ahmed_new.jpg', 'testing_data/ahmed1.1.jpeg', 'testing_data/fouz.jpeg', 'testing_data/fouzan.jpeg','testing_data/ahmed1.2.jpeg']\n",
    "# get embeddings file filenames\n",
    "embeddings = get_embeddings(filenames)\n",
    "print(embeddings[0].shape)\n",
    "print(embeddings[1].shape)\n",
    "# # define sharon stone\n",
    "# sharon_id = embeddings[0]\n",
    "# # verify known photos of sharon\n",
    "print('Positive Tests')\n",
    "is_match(embeddings[0], embeddings[4])\n",
    "# is_match(embeddings[0], embeddings[2])em\n",
    "# # verify known photos of other people\n",
    "print('Negative Tests')\n",
    "is_match(embeddings[0], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53d2391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: train=100.0, test=100.0\n"
     ]
    }
   ],
   "source": [
    "trainy = [0,0,1,1,0]\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(embeddings, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(embeddings)\n",
    "yhat_test = model.predict(embeddings)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(trainy, yhat_test)\n",
    "\n",
    "# summarize\n",
    "print(f\"Accuracy: train={score_train*100}, test={score_test*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea16a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a213b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
